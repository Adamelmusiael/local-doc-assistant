# Default LLM model
DEFAULT_LLM_MODEL=mistral

# Default confidentiality levels
CONFIDENTIALITY_OPTIONS=public,internal,confidential

# Local models that can access confidential data
LOCAL_MODELS=mistral,llama3.1-8b-128k,qwen2.5-1m

# External models that cannot access confidential data
EXTERNAL_MODELS=gpt-4o,gpt-4-turbo,gpt-3.5-turbo,gpt-4.1,gpt-4.1-mini,gpt-4.1-nano

# OpenAI models that require API key
OPENAI_MODELS=gpt-4o,gpt-4-turbo,gpt-3.5-turbo,gpt-4.1,gpt-4.1-mini,gpt-4.1-nano

# All allowed models (local and OpenAI)
ALLOWED_MODELS=mistral,llama3.1-8b-128k,qwen2.5-1m,gpt-4o,gpt-4-turbo,gpt-3.5-turbo,gpt-4.1,gpt-4.1-mini,gpt-4.1-nano

# Model name mapping for Ollama (friendly_name=ollama_name)
MODEL_MAPPING=mistral=mistral:latest,llama3.1-8b-128k=llama3.1:8b-instruct-q4_K_M,qwen2.5-1m=qwen2.5:latest 

# Dynamic Chunk Selection Configuration
MIN_CHUNKS=3
MAX_CHUNKS=25
SIMPLE_QUERY_CHUNKS=5
MEDIUM_QUERY_CHUNKS=10
COMPLEX_QUERY_CHUNKS=15
COMPREHENSIVE_QUERY_CHUNKS=25

# Enhanced Chunking Configuration
DEFAULT_CHUNK_SIZE=512
MAX_CHUNK_SIZE=1024
DEFAULT_TOKEN_OVERLAP=150
TECHNICAL_CONTENT_OVERLAP_RATIO=0.20
LEGAL_CONTENT_OVERLAP_RATIO=0.25
NARRATIVE_CONTENT_OVERLAP_RATIO=0.10
GENERAL_CONTENT_OVERLAP_RATIO=0.15
MAX_TOKEN_LIMIT=8192 